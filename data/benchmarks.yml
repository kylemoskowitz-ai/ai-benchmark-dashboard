# Benchmark definitions
# These are loaded during initialization and can be extended.

benchmarks:
  swe_bench_verified:
    name: "SWE-Bench Verified"
    category: "coding"
    description: "SWE-Bench evaluates models on real GitHub issues. The Verified subset contains 500 human-verified test cases."
    unit: "percent"
    scale_min: 0
    scale_max: 100
    higher_is_better: true
    official_url: "https://www.swebench.com/"
    paper_url: "https://arxiv.org/abs/2310.06770"

  metr_time_horizons:
    name: "METR Time Horizons"
    category: "agentic"
    description: "METR evaluates AI agents on long-horizon autonomous tasks."
    unit: "hours"
    scale_min: 0
    scale_max: 1000
    higher_is_better: true
    official_url: "https://metr.org/"
    paper_url: "https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/"

  frontiermath_tier4:
    name: "FrontierMath (Tier 4)"
    category: "math"
    description: "FrontierMath Tier 4 contains the most challenging mathematical problems."
    unit: "percent"
    scale_min: 0
    scale_max: 100
    higher_is_better: true
    official_url: "https://epoch.ai/frontiermath"
    paper_url: "https://arxiv.org/abs/2411.04872"

  arc_agi_1:
    name: "ARC-AGI 1"
    category: "reasoning"
    description: "Original Abstraction and Reasoning Corpus evaluating fluid intelligence and novel problem solving."
    unit: "percent"
    scale_min: 0
    scale_max: 100
    higher_is_better: true
    official_url: "https://arcprize.org/"
    paper_url: "https://arxiv.org/abs/1911.01547"

  arc_agi_2:
    name: "ARC-AGI 2"
    category: "reasoning"
    description: "Updated ARC-AGI with harder tasks and improved evaluation methodology."
    unit: "percent"
    scale_min: 0
    scale_max: 100
    higher_is_better: true
    official_url: "https://arcprize.org/arc-agi-2"

  gpqa_diamond:
    name: "GPQA Diamond"
    category: "reasoning"
    description: "Graduate-level science questions requiring expert knowledge."
    unit: "percent"
    scale_min: 0
    scale_max: 100
    higher_is_better: true
    official_url: "https://arxiv.org/abs/2311.12022"

  mmmu:
    name: "MMMU"
    category: "multimodal"
    description: "Massive Multi-discipline Multimodal Understanding - evaluates multimodal models on college-level tasks."
    unit: "percent"
    scale_min: 0
    scale_max: 100
    higher_is_better: true
    official_url: "https://mmmu-benchmark.github.io/"
    paper_url: "https://arxiv.org/abs/2311.16502"
